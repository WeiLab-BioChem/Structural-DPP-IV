{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. verify feasibility"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1355,  0.0609, -1.4057,  2.0294],\n",
      "        [ 1.3597, -1.9034,  0.3689,  0.4662],\n",
      "        [ 0.3267,  1.0722, -0.6470,  0.0347],\n",
      "        [ 2.1075, -1.1362,  1.3582, -1.1645],\n",
      "        [-0.2258,  0.0294,  1.9978, -0.6777],\n",
      "        [ 0.4525,  1.6634,  1.6871, -1.3138]])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[-0.1355,  0.0609, -1.4057,  1.0000,  2.0294],\n",
      "        [ 1.3597, -1.9034,  0.3689,  1.0000,  0.4662],\n",
      "        [ 0.3267,  1.0722, -0.6470,  1.0000,  0.0347],\n",
      "        [ 2.1075, -1.1362,  1.3582,  1.0000, -1.1645],\n",
      "        [-0.2258,  0.0294,  1.9978,  1.0000, -0.6777],\n",
      "        [ 0.4525,  1.6634,  1.6871,  1.0000, -1.3138]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "n = torch.randn([6,4])\n",
    "p = torch.ones(n.shape[0])\n",
    "p = p.unsqueeze(1)\n",
    "print(n)\n",
    "print(p)\n",
    "n_1 = torch.cat((n[:,:3],p, n[:,3:]),1)\n",
    "# n_2 = torch.cat((n_1, n[:,4:]),1)\n",
    "print(n_1)\n",
    "# print(n_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. import basic setting and model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using Structural config of DPP-IV\n",
      "[INFO] using CNN config of DPP-IV\n",
      "dict_keys(['Ws', 'Wh', 'StructEncodeModule.conv.weight', 'StructEncodeModule.conv.bias', 'StructEncodeModule.resBlock1.conv.weight', 'StructEncodeModule.resBlock1.conv.bias', 'StructEncodeModule.resBlock1.conv1.weight', 'StructEncodeModule.resBlock1.conv1.bias', 'StructEncodeModule.resBlock1.batchnorm1.weight', 'StructEncodeModule.resBlock1.batchnorm1.bias', 'StructEncodeModule.resBlock1.batchnorm1.running_mean', 'StructEncodeModule.resBlock1.batchnorm1.running_var', 'StructEncodeModule.resBlock1.batchnorm1.num_batches_tracked', 'StructEncodeModule.resBlock1.conv2.weight', 'StructEncodeModule.resBlock1.conv2.bias', 'StructEncodeModule.resBlock1.batchnorm2.weight', 'StructEncodeModule.resBlock1.batchnorm2.bias', 'StructEncodeModule.resBlock1.batchnorm2.running_mean', 'StructEncodeModule.resBlock1.batchnorm2.running_var', 'StructEncodeModule.resBlock1.batchnorm2.num_batches_tracked', 'StructEncodeModule.resBlock2.conv.weight', 'StructEncodeModule.resBlock2.conv.bias', 'StructEncodeModule.resBlock2.conv1.weight', 'StructEncodeModule.resBlock2.conv1.bias', 'StructEncodeModule.resBlock2.batchnorm1.weight', 'StructEncodeModule.resBlock2.batchnorm1.bias', 'StructEncodeModule.resBlock2.batchnorm1.running_mean', 'StructEncodeModule.resBlock2.batchnorm1.running_var', 'StructEncodeModule.resBlock2.batchnorm1.num_batches_tracked', 'StructEncodeModule.resBlock2.conv2.weight', 'StructEncodeModule.resBlock2.conv2.bias', 'StructEncodeModule.resBlock2.batchnorm2.weight', 'StructEncodeModule.resBlock2.batchnorm2.bias', 'StructEncodeModule.resBlock2.batchnorm2.running_mean', 'StructEncodeModule.resBlock2.batchnorm2.running_var', 'StructEncodeModule.resBlock2.batchnorm2.num_batches_tracked', 'StructEncodeModule.linear.weight', 'StructEncodeModule.linear.bias', 'TextCNN.embedding.weight', 'TextCNN.convs.0.weight', 'TextCNN.convs.0.bias', 'TextCNN.convs.1.weight', 'TextCNN.convs.1.bias', 'TextCNN.linear.weight', 'TextCNN.linear.bias', 'classification.0.weight', 'classification.0.bias', 'classification.3.weight', 'classification.3.bias'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "sys.path.append(\"/mnt/8t/jjr/Structural-DPP-IV\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# from model import StructuralDPPIV\n",
    "from config import load_config\n",
    "from config.load_constant import constant\n",
    "from data import StructuralEncode\n",
    "from data import Encode\n",
    "from util import util_draw\n",
    "\n",
    "config_dict = load_config.load_default_args_dict(\"StructuralDPPIV\")\n",
    "config_dict['max_epochs'] = 150\n",
    "config_dict['gpus'] = [3]  # using which GPU to train\n",
    "config_dict['batch_size'] = 32\n",
    "config_dict['lr'] = 0.000005\n",
    "config_dict['model'] = 'StructuralDPPIV'\n",
    "config_dict['log_dir'] = constant['path_log']\n",
    "config_dict['max_seq_len'] = 90\n",
    "args = argparse.Namespace(**config_dict)\n",
    "\n",
    "class StructuralDPPIV(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(StructuralDPPIV, self).__init__()\n",
    "        self.StructEncodeModule = Structural(config)\n",
    "        self.TextCNN = TextCNN()\n",
    "\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear(1024, 64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "        self.Ws = nn.Parameter(torch.randn(1, 1024).cuda(), requires_grad=True)\n",
    "        self.Wh = nn.Parameter(torch.randn(1, 1024).cuda(), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        TextCNN_Only = False\n",
    "        StructuralEncodingOnly = False\n",
    "        assert not (TextCNN_Only and StructuralEncodingOnly)\n",
    "        if not TextCNN_Only and not StructuralEncodingOnly:\n",
    "            TextCNNEncode = self.TextCNN(x[0])\n",
    "            StructedEncode = self.StructEncodeModule(x[1])\n",
    "            newEncode = TextCNNEncode * StructedEncode\n",
    "            output = self.classification(newEncode)\n",
    "            return output, newEncode\n",
    "        elif TextCNN_Only:\n",
    "            TextCNNEncode = self.TextCNN(x[0])\n",
    "            output = self.classification(TextCNNEncode)\n",
    "            return output, TextCNNEncode\n",
    "        elif StructuralEncodingOnly:\n",
    "            StructedEncode = self.StructEncodeModule(x[1])\n",
    "            output = self.classification(StructedEncode)\n",
    "            return output, StructedEncode\n",
    "\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.visualization = False\n",
    "        vocab_size = 24\n",
    "        dim_embedding = 100\n",
    "        print(f\"[INFO] using CNN config of {dataset_name}\")\n",
    "        # filter_sizes = [1, 2, 4, 8, 16, 24, 32, 48, 64]\n",
    "        filter_sizes = [1, 2]\n",
    "        filter_num = 90\n",
    "        self.embedding = nn.Embedding(vocab_size, dim_embedding)\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, filter_num, (fsz, dim_embedding)) for fsz in filter_sizes])\n",
    "        self.linear = nn.Linear(filter_num * len(filter_sizes), 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"\\nx = \\n\", x)\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(x.size(0), 1, x.size(1), -1)\n",
    "        x = [F.relu(conv(x)) for conv in self.convs]\n",
    "\n",
    "        x = [F.max_pool2d(input=x_item, kernel_size=(x_item.size(2), x_item.size(3))) for x_item in x]\n",
    "        x = [x_item.view(x_item.size(0), -1) for x_item in x]\n",
    "        embedding = torch.cat(x, 1)\n",
    "        embedding = self.linear(embedding)\n",
    "\n",
    "        return embedding\n",
    "\n",
    "\n",
    "class Structural(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Structural, self).__init__()\n",
    "        self.config = config\n",
    "        self.inpuchannel = [32, 32, 64]\n",
    "        global dataset_name\n",
    "        dataset_name = 'DPP-IV'\n",
    "        print(f\"[INFO] using Structural config of {dataset_name}\")\n",
    "        self.embedding_dim = 21\n",
    "        global max_seq_len\n",
    "        max_seq_len = config.max_seq_len\n",
    "        self.conv = torch.nn.Conv2d(self.embedding_dim, self.inpuchannel[0], (3, 3), stride=1, padding='same')\n",
    "        # self.conv = torch.nn.Conv2d(19, self.inpuchannel[0], (3, 3), stride=1, padding='same')\n",
    "        self.resBlock1 = resBlock(self.inpuchannel[0], self.inpuchannel[1])\n",
    "        self.resBlock2 = resBlock(self.inpuchannel[1], self.inpuchannel[2], increDimen=True)\n",
    "        self.linear = nn.Linear(23552, 1024)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        # 90 is the max length of sequence, 15 is the number of amino acid, 21 is the number of channel\n",
    "        graph = graph.cuda()  # (batchSize, 90, 15, 21)\n",
    "        # graph = graph.transpose(2, 3)  # (batchSize, 90, 21, 15)\n",
    "        # graph = graph.transpose(1, 2)   # (batchSize, 21, 90, 15)\n",
    "        representation = self.conv(graph) # (batchSize, 32, 90, 15)\n",
    "        representation = self.resBlock1(representation) # (batchSize, 32, 90, 15)\n",
    "        representation = self.resBlock2(representation) # (batchSize, 64, 46, 8)\n",
    "        representation = representation.flatten(start_dim=1) # (batchSize, 23552)\n",
    "        representation = self.linear(representation) # (batchSize, 1024)\n",
    "        return representation\n",
    "\n",
    "\n",
    "class resBlock(nn.Module):\n",
    "    def __init__(self, inputchannel, outputchannel, increDimen=False):\n",
    "        super(resBlock, self).__init__()\n",
    "        self.increDimen = increDimen\n",
    "        self.inputchannel = inputchannel\n",
    "        self.outputchannel = outputchannel\n",
    "        padding_dim1 = 2 if max_seq_len % 2 == 0 else 1\n",
    "        self.conv = torch.nn.Conv2d(inputchannel, outputchannel, (3, 3), stride=(2, 2), padding=(padding_dim1, 1))\n",
    "        self.conv1 = torch.nn.Conv2d(inputchannel, outputchannel, (3, 3), stride=1, padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(inputchannel, affine=True)\n",
    "        self.conv2 = torch.nn.Conv2d(outputchannel, outputchannel, (3, 3), stride=1, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(outputchannel, affine=True)\n",
    "\n",
    "    def forward(self, feature):\n",
    "        original = feature\n",
    "\n",
    "        if self.increDimen:\n",
    "            feature = F.max_pool2d(input=feature, kernel_size=(2, 2), padding=1)\n",
    "            original = self.conv(original)\n",
    "        feature = self.batchnorm1(feature)\n",
    "        feature = F.relu(feature)\n",
    "        feature = self.conv1(feature)\n",
    "        feature = self.batchnorm2(feature)\n",
    "        feature = F.relu(feature)\n",
    "        feature = self.conv2(feature)\n",
    "        feature = feature + original\n",
    "        return feature\n",
    "\n",
    "def load_params(model, param_path):\n",
    "    pretrained_dict = torch.load(param_path)['state_dict']\n",
    "    # print(pretrained_dict.keys())\n",
    "    new_model_dict = model.state_dict()\n",
    "    # print(new_model_dict.keys())\n",
    "    pretrained_dict = {'.'.join(k.split('.')[1:]): v for k, v in pretrained_dict.items() if '.'.join(k.split('.')[1:]) in new_model_dict}\n",
    "    # pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if k[6:] in new_model_dict}\n",
    "    print(pretrained_dict.keys())\n",
    "    new_model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(new_model_dict)\n",
    "\n",
    "def get_one_sequence_code(sequence = 'YPFPGPIP'):\n",
    "    # sequence = 'YPFPGPIP'\n",
    "\n",
    "    sequence_data_process = Encode.codePeptides([sequence])\n",
    "    sequence_data_length = len(sequence_data_process[0])\n",
    "    sequence_data_padding = np.pad(sequence_data_process[0], (0, 90 - sequence_data_length), 'constant', constant_values=0)\n",
    "    sequence_data = torch.tensor(np.array([sequence_data_padding])).cuda()\n",
    "\n",
    "    Channel = StructuralEncode.convert_to_graph_channel(sequence)\n",
    "    Structure_data = StructuralEncode.convert_to_graph_channel_returning_maxSeqLenx15xfn(Channel, cubeBiased=False,\n",
    "                                                                 maxSeqLen=90, cubeBias=False,\n",
    "                                                                 right_align=False)\n",
    "    tensor_Structure_data = torch.tensor(Structure_data).cuda()\n",
    "    tensor_Structure_data = torch.unsqueeze(tensor_Structure_data, 0)\n",
    "    tensor_Structure_data = tensor_Structure_data.transpose(2, 3)  # (batchSize, 90, 21, 15)\n",
    "    tensor_Structure_data = tensor_Structure_data.transpose(1, 2)   # (batchSize, 21, 90, 15)\n",
    "\n",
    "    # sequence_data = sequence_data_process.cuda()\n",
    "    # print(sequence_data)\n",
    "    return [sequence_data, tensor_Structure_data]\n",
    "\n",
    "def load_tsv(filename, skip_head=True):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as file:\n",
    "        if skip_head:\n",
    "            next(file)\n",
    "        for line in file:\n",
    "            if line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            list = line.split('\\t')\n",
    "            sequences.append(list[2])\n",
    "            labels.append(int(list[1]))\n",
    "    return sequences, labels\n",
    "\n",
    "new_model = StructuralDPPIV(args).cuda()\n",
    "load_params(new_model, '/mnt/8t/jjr/Structural-DPP-IV/main/log/StructuralDPPIV/version_3/checkpoints/epoch=73,step=2442,val_SE_epoch=0.95,val_SP_epoch=0.87,val_F1_epoch=0.91,val_AUC_epoch=1.00.ckpt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_model.eval()\n",
    "pred_prob = []\n",
    "label_pred = []\n",
    "predict_true = 0\n",
    "\n",
    "sequences, labels = load_tsv('/mnt/8t/jjr/Structural-DPP-IV/data/DPP-IV/test/test.tsv')\n",
    "# sequences, labels = load_tsv('/mnt/8t/jjr/Structural-DPP-IV/data/DPP-IV/train/train.tsv')\n",
    "from tqdm import tqdm\n",
    "# predict sequence one by one\n",
    "for index in tqdm(range(len(sequences))):\n",
    "    # print(\"before success2:\", config.learn_name)\n",
    "    sequence_code = get_one_sequence_code(sequences[index])\n",
    "    logits, representation = new_model(sequence_code)\n",
    "\n",
    "    pred_prob_all = F.softmax(logits, dim=1)  # predict probability [batch_size, class_num]\n",
    "    pred_prob_positive = pred_prob_all[:, 1]  # note, it is very easy to make mistake\n",
    "    pred_prob_sort = torch.max(pred_prob_all, 1)  # max probability in each sample [batch_size]\n",
    "    pred_class = pred_prob_sort[1]  # where max probability site in each sample [batch_size]\n",
    "\n",
    "    pred_prob = pred_prob + pred_prob_positive.tolist()\n",
    "    label_pred = label_pred + pred_class.tolist()\n",
    "\n",
    "acc = accuracy_score(labels, label_pred)\n",
    "auc = roc_auc_score(labels, pred_prob)\n",
    "f1 = f1_score(labels, label_pred)\n",
    "se = recall_score(labels, label_pred)\n",
    "sp = recall_score(labels, label_pred, pos_label=0)\n",
    "\n",
    "print('acc:', acc)\n",
    "print('auc:', auc)\n",
    "print('f1:', f1)\n",
    "print('se:', se)\n",
    "print('sp:', sp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. permutation importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fea_dict = {'symbol':[0,1,2,3], 'degree':[4,5,6], 'num_h':[7,8,9,10], 'num_h_implicit':[11,12,13,14], 'aromatic':[15], 'ring':[16,17]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequences, labels = load_tsv('/mnt/8t/jjr/Structural-DPP-IV/data/DPP-IV/test/test.tsv')\n",
    "sequences_token_origin = []\n",
    "sequences_token_permutation = []\n",
    "for sequence in sequences:\n",
    "    sequences_token_origin.append(get_one_sequence_code(sequence))\n",
    "\n",
    "permutation_index = np.random.permutation([i for i in range(len(sequences))])\n",
    "\n",
    "for i in range(len(sequences)):\n",
    "    structural_encode_origin = sequences_token_origin[i][1]\n",
    "    structural_encode_target = sequences_token_origin[permutation_index[i]][1].index_select(1,torch.tensor([20]).cuda())\n",
    "    structural_encode_permutation = torch.cat((structural_encode_origin[:,:20,:,:], structural_encode_target, structural_encode_origin[:,21:,:,:]),1)\n",
    "\n",
    "    sequences_token_permutation.append([sequences_token_origin[i][0], structural_encode_permutation])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 21, 90, 15])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_token_permutation[0][1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 266/266 [00:00<00:00, 409.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.849624060150376\n",
      "auc: 0.944767934874781\n",
      "f1: 0.8473282442748092\n",
      "se: 0.8345864661654135\n",
      "sp: 0.8646616541353384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_model.eval()\n",
    "pred_prob = []\n",
    "label_pred = []\n",
    "predict_true = 0\n",
    "\n",
    "# sequences, labels = load_tsv('/mnt/8t/jjr/Structural-DPP-IV/data/DPP-IV/test/test.tsv')\n",
    "# sequences, labels = load_tsv('/mnt/8t/jjr/Structural-DPP-IV/data/DPP-IV/train/train.tsv')\n",
    "from tqdm import tqdm\n",
    "# predict sequence one by one\n",
    "for index in tqdm(range(len(sequences))):\n",
    "    # print(\"before success2:\", config.learn_name)\n",
    "    # sequence_code = get_one_sequence_code(sequences[index])\n",
    "    logits, representation = new_model(sequences_token_permutation[index])\n",
    "\n",
    "    pred_prob_all = F.softmax(logits, dim=1)  # predict probability [batch_size, class_num]\n",
    "    pred_prob_positive = pred_prob_all[:, 1]  # note, it is very easy to make mistake\n",
    "    pred_prob_sort = torch.max(pred_prob_all, 1)  # max probability in each sample [batch_size]\n",
    "    pred_class = pred_prob_sort[1]  # where max probability site in each sample [batch_size]\n",
    "\n",
    "    pred_prob = pred_prob + pred_prob_positive.tolist()\n",
    "    label_pred = label_pred + pred_class.tolist()\n",
    "\n",
    "acc = accuracy_score(labels, label_pred)\n",
    "auc = roc_auc_score(labels, pred_prob)\n",
    "f1 = f1_score(labels, label_pred)\n",
    "se = recall_score(labels, label_pred)\n",
    "sp = recall_score(labels, label_pred, pos_label=0)\n",
    "\n",
    "print('acc:', acc)\n",
    "print('auc:', auc)\n",
    "print('f1:', f1)\n",
    "print('se:', se)\n",
    "print('sp:', sp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}